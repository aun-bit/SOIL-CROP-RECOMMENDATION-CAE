# Soil–Crop Recommendation System using Convolutional Autoencoder (CAE)

## Abstract / Overview

This project builds a **soil–crop recommendation system** that predicts the most suitable crop based on soil nutrients and environmental conditions. We use a **Convolutional Autoencoder (CAE)–based classifier** as the main model and a **Logistic Regression** baseline for comparison. Models are trained on the Kaggle **Crop Recommendation Dataset** and evaluated using accuracy, precision, recall, and F1-score. The work supports **SDG 2 (Zero Hunger)** and **SDG 12 (Responsible Consumption and Production)** by enabling data‑driven, sustainable crop planning.

---

## 1. Introduction

Crop choice is often based on experience or generic advisories, which may not fully reflect **field‑specific soil and climate conditions**. This can lead to suboptimal yields, wasted fertilizers and water, and economic losses. With soil testing and meteorological data becoming widely available, there is an opportunity to use **machine learning** for objective crop recommendation.

**Objectives:**

1. Design a **CAE‑based deep learning model** for soil–crop recommendation.
2. Implement a **Logistic Regression baseline** on standardized raw features.
3. Evaluate both models using accuracy, precision, recall, and F1-score.
4. Provide a simple **inference pipeline** to recommend crops for new soil inputs.
5. Relate the solution to **SDG 2** and **SDG 12**.

---

## 2. Dataset

- **Source:** Kaggle – Crop Recommendation Dataset (`Crop_recommendation.csv`).
- **Path:** `data/soil_crop/Crop_recommendation.csv`.
- **Size:** ~2200 samples, **22 crop classes**.
- **Features (7):**  
  `N, P, K, temperature, humidity, ph, rainfall`
- **Label:** `label` – crop name (22 classes).

**Preprocessing (implemented in `utils/data_loader.py`):**

- Stratified **train/validation/test split** (~70%/15%/15%).
- **Standardization** of features using `StandardScaler`.
- **Label encoding** using `LabelEncoder`.
- For CAE, features reshaped from `(7,)` to `(7, 1)` for Conv1D input.

---

## 3. Methodology

### 3.1 Baseline Model – Logistic Regression

- Input: standardized `[N, P, K, temperature, humidity, ph, rainfall]`.
- Model: scikit‑learn `LogisticRegression` (`max_iter=500`, `solver="lbfgs"`).
- Trained on train+val, evaluated on test.
- Script: `baseline_logreg.py`.

### 3.2 Main Model – CAE‑Based Classifier

**Encoder (Conv1D):**

- Input shape `(7, 1)`.
- `Conv1D(16, k=3, activation="relu", padding="same")`
- `Conv1D(8, k=3, strides=2, activation="relu", padding="same")`
- `Flatten()` → latent vector.

**Decoder (Autoencoder):**

- `UpSampling1D(2)`
- `Conv1D(16, k=3, activation="relu", padding="same")`
- `Conv1D(1, k=3, activation="linear", padding="same")`
- Crop to length 7 → reconstructed `(7, 1)`.

**Classifier head:**

- `Dense(64, "relu")`
- `Dense(22, "softmax")` (22 crops).

**Training:**

1. **Stage 1 – Autoencoder pretraining**  
   - Loss: MSE, Epochs: 20, Batch size: 32.
2. **Stage 2 – Classifier training**  
   - Loss: sparse categorical cross‑entropy, Epochs: 50, Batch size: 32, Optimizer: Adam.

Scripts: `model.py`, `train.py`, `evaluate.py`.

---

## 4. Experimental Setup

- **Splits:** 1540 train, 330 val, 330 test (stratified).
- **Metrics:** Accuracy, Precision (weighted), Recall (weighted), F1‑score (weighted).
- **Environment:**  
  - Python 3.11, TensorFlow/Keras, scikit‑learn, NumPy, Pandas.  
  - Developed in VS Code on Windows, also tested in Google Colab (CPU).

---

## 5. Results

### 5.1 Baseline vs Main Model

| Model                          | Accuracy | Precision (w) | Recall (w) | F1 (w)  |
|--------------------------------|----------|---------------|------------|---------|
| Logistic Regression (baseline) | 97.58%   | 97.64%        | 97.58%     | 97.55%  |
| CAE‑based classifier (main)    | 99.09%   | 99.15%        | 99.09%     | 99.09%  |

The Logistic Regression baseline is already very strong, but the CAE‑based classifier improves accuracy and F1 by about **+1.5 percentage points**, showing the benefit of non‑linear representation learning.

### 5.2 Visualizations

Images are in `docs/figures/` (generated by `visualize_results.py`):

- `ae_loss_curve.png` – Autoencoder training/validation loss vs epochs.  
- `classifier_loss_curve.png` – Classifier loss (train/val).  
- `classifier_accuracy_curve.png` – Classifier accuracy (train/val).  
- `confusion_matrix.png` – Confusion matrix on test set (nearly all mass on diagonal).  
- `roc_curve_micro.png`, `precision_recall_curve_micro.png` – Micro‑averaged ROC and PR curves showing high AUC/AP.

---

## 6. Discussion

**What worked well:**

- CAE encoder learns a useful latent representation from only 7 features.  
- Two‑stage training (AE pretraining + classifier) is stable and converges quickly.  
- CAE‑based model clearly outperforms a strong Logistic Regression baseline.

**Challenges and lessons:**

- Handling environment differences (Colab vs local VS Code, TensorFlow weight naming).  
- Ensuring reproducible preprocessing (same scaler and label encoder for training, eval, and inference).  
- Balancing model complexity with small input dimension to avoid overfitting.

---

Markdown

## 7. Installation and Usage

### 7.1 Installation

    ```bash
    pip install -r requirements.txt

Ensure `Crop_recommendation.csv` is placed under `data/soil_crop/`.

### 7.2 Training
    ```bash
    python train.py

### 7.3 Evaluation
    ```bash
    python evaluate.py
    python baseline_logreg.py

### 7.4 Inference
    ```bash
    python inference.py --input_json sample_input.json --top_k 3

### 7.5 Visualization
    ```bash
    python visualize_results.py

Plots will be saved to `docs/figures/`.

## 8. Conclusion and Future Work

This project demonstrates that a CAE‑based classifier can achieve **99.09% accuracy** on the Crop Recommendation dataset, outperforming a strong Logistic Regression baseline (**97.58%**). The system forms a reproducible, SDG‑aligned pipeline for soil–crop recommendation that can be extended to real‑world data.

**Future work:**

- Evaluation on noisy, real‑world soil datasets from different regions.  
- Additional baselines (Random Forest, XGBoost, TabNet, Transformers).  
- Web or mobile UI for farmer‑friendly deployment.

## 9. References

[1] M. K. Senapaty, A. Ray, and N. Padhy, “A Decision Support System for Crop Recommendation Using Machine Learning Classification Algorithms,” *Agriculture*, vol. 14, no. 8, 1256, 2024. doi: 10.3390/agriculture14081256.  
[2] Y. Akkem, S. K. Biswas, and A. Varanasi, “A Comprehensive Review of Synthetic Data Generation in Smart Farming by Using Variational Autoencoder and Generative Adversarial Network,” *Engineering Applications of Artificial Intelligence*, 2024. doi: 10.1016/j.engappai.2024.107881.  
[3] P.-Y. Kow, Y.-T. Wang, Y.-W. Chang, M.-H. Lee, M.-H. Yao, and L.-C. Chang, “AI-driven Weather Downscaling for Smart Agriculture Using Autoencoders and Transformers,” *Computers and Electronics in Agriculture*, 2025. doi: 10.1016/j.compag.2025.110129.  
[4] C. Barroso-Barroso, A. Vega-Muñoz, J. Maradiaga-López, G. Salazar-Sepúlveda, and R. Carabantes-Silva, “Smart Farming and the SDGs: Emerging Research Patterns and Sustainability Implications,” *Agriculture*, vol. 16, no. 1, 81, 2026. doi: 10.3390/agriculture16010081.  
[5] A. Basuki, A. D. Cahyani, Y. P. D. Negara, I. O. Suzanti, S. N. M. Hanstanti, M. Yusuf, and B. K. Khotimah, “Advancing SDG 2 Through Smart Agriculture: Modeling Technology Adoption Among Indonesian Farmers Using the UTAUT2 Framework,” *SDGsReview*, vol. 5, e07624, 2025. doi: 10.47172/2965-730X.SDGsReview.v5.n08.pe07624.  
[6] P. Seethapathy, R. Preetha, M. Jeya Rani, K. Kalaichelvi, and P. M. Sankar, “Digitalization in Smart Farming,” in *AgriTech Revolution*, book chapter, pp. 303–330, 2025.  
[7] A. Ray, A. K. Srivastava, S. Singh, and M. Bar, “Introduction to Smart Technologies to Ensure Zero Hunger: SDG2,” in *Smart Technologies for Sustainable Development Goals*, 1st ed., CRC Press, 2025.  
[8] S. Shastri, S. Kumar, V. Mansotra, and R. Salgotra, “Advancing Crop Recommendation System with Supervised Machine Learning and Explainable Artificial Intelligence,” *Scientific Reports*, vol. 15, 25498, 2025.  
[9] H. Afzal, M. Amjad, A. Raza, K. Munir, S. G. Villar, L. A. D. Lopez, and I. Ashraf, “Incorporating Soil Information with Machine Learning for Crop Recommendation to Improve Agricultural Output,” *Scientific Reports*, vol. 15, 8560, 2025.  
[10] D. Dahiphale, P. Shinde, K. Patil, and V. Dahiphale, “Smart Farming: Crop Recommendation Using Machine Learning with Challenges and Future Ideas,” *AIA*, 2026. doi: 10.47852/bonviewAIA52026214.  
[11] K. Shekhar, S. Gugulothu, P. Sadhashiva, H. Moutam, and B. Divyasri, “Machine Learning-Based Crop Recommendation System for Enhanced Yield Production,” *Journal of Computational Analysis & Applications*, vol. 34, no. 4, p. 428, 2025.  
[12] M. S. B. Alam, V. Esichaikul, A. Lameesa, S. F. Ahmed, and A. H. Gandomi, “An Approach for Crop Recommendation with Uncertainty Quantification Based on Machine Learning for Sustainable Agricultural Decision-Making,” *Results in Engineering*, 2025. doi: 10.1016/j.rineng.2025.105505.
